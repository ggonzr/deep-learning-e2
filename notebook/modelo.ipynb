{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b243b22-1b39-448d-9a9c-ca6e40ae53d1",
   "metadata": {},
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c988bc-5503-4764-8896-40fceb43ca5d",
   "metadata": {},
   "source": [
    "Iteración rápida con un modelo de U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "835511b9-f366-43e0-8a78-50f5f5232d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from matplotlib import colors\n",
    "from skimage import exposure\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# =================\n",
    "# Tensorflow\n",
    "# =================\n",
    "\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout, MaxPool2D, UpSampling2D, Concatenate\n",
    "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n",
    "from keras.layers.merge import concatenate, add\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "from scipy import ndimage\n",
    "\n",
    "#=========================\n",
    "\n",
    "import rasterio as rio\n",
    "import rasterio.plot as rio_plot\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import json\n",
    "import typing as typ\n",
    "# Semilla pseudoaleatoria\n",
    "np.random.seed(24)\n",
    "\n",
    "# Tamaño de las figuras\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "\n",
    "# Ruta base de la carpeta de datos\n",
    "DATA_BASE = \"/home/ggonzr_cloud/deeplearn/data\"\n",
    "\n",
    "# Imagen\n",
    "HEIGHT = 256\n",
    "WIDTH = 256\n",
    "CHANNELS = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e724c7-4077-4df4-8fbb-d817599ee15e",
   "metadata": {},
   "source": [
    "## Definición del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dcca69-c0ce-4c56-806d-9070575109b1",
   "metadata": {},
   "source": [
    "### Version del laboratorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92728218-df5c-4a3b-9fba-90ce4631f679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_block(input_tensor, n_filters, kernel_size = 3, batchnorm = True):\n",
    "    \"\"\"Function to add 2 convolutional layers with the parameters passed to it\"\"\"\n",
    "    # first layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    # second layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1ef91db-5d0f-430d-adcf-24238341129a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet(input_img, n_filters = 16, dropout = 0.1, batchnorm = True):\n",
    "    \"\"\"Function to define the UNET Model\"\"\"\n",
    "    # Contracting Path (Encoder)\n",
    "    c1 = conv2d_block(input_img, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    p1 = Dropout(dropout)(p1)\n",
    "    \n",
    "    c2 = conv2d_block(p1, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "    p2 = Dropout(dropout)(p2)\n",
    "    \n",
    "    c3 = conv2d_block(p2, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "    p3 = Dropout(dropout)(p3)\n",
    "    \n",
    "    c4 = conv2d_block(p3, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "    p4 = Dropout(dropout)(p4)\n",
    "    \n",
    "    c5 = conv2d_block(p4, n_filters = n_filters * 16, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    # Expansive Path (Decoder)\n",
    "    u6 = Conv2DTranspose(n_filters * 8, (3, 3), strides = (2, 2), padding = 'same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    u6 = Dropout(dropout)(u6)\n",
    "    c6 = conv2d_block(u6, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    u7 = Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    u7 = Dropout(dropout)(u7)\n",
    "    c7 = conv2d_block(u7, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    u8 = Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    u8 = Dropout(dropout)(u8)\n",
    "    c8 = conv2d_block(u8, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    u9 = Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(c8)\n",
    "    u9 = concatenate([u9, c1])\n",
    "    u9 = Dropout(dropout)(u9)\n",
    "    c9 = conv2d_block(u9, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "    model = Model(inputs=[input_img], outputs=[outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77e9594-efe5-4b3a-b1a9-e92dbd6d813f",
   "metadata": {},
   "source": [
    "### Versión V2\n",
    "\n",
    "Link: https://github.com/nikhilroxtomar/Multiclass-Segmentation-in-Unet/blob/master/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c692602-90c6-4992-a9b4-73e6fa8f9574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(inputs, filters, pool=True):\n",
    "    x = Conv2D(filters, 3, padding=\"same\")(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(filters, 3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    if pool == True:\n",
    "        p = MaxPool2D((2, 2))(x)\n",
    "        return x, p\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def build_unet(shape, num_classes):\n",
    "    inputs = Input(shape)\n",
    "\n",
    "    \"\"\" Encoder \"\"\"\n",
    "    x1, p1 = conv_block(inputs, 16, pool=True)\n",
    "    x2, p2 = conv_block(p1, 32, pool=True)\n",
    "    x3, p3 = conv_block(p2, 48, pool=True)\n",
    "    x4, p4 = conv_block(p3, 64, pool=True)\n",
    "\n",
    "    \"\"\" Bridge \"\"\"\n",
    "    b1 = conv_block(p4, 128, pool=False)\n",
    "\n",
    "    \"\"\" Decoder \"\"\"\n",
    "    u1 = UpSampling2D((2, 2), interpolation=\"bilinear\")(b1)\n",
    "    c1 = Concatenate()([u1, x4])\n",
    "    x5 = conv_block(c1, 64, pool=False)\n",
    "\n",
    "    u2 = UpSampling2D((2, 2), interpolation=\"bilinear\")(x5)\n",
    "    c2 = Concatenate()([u2, x3])\n",
    "    x6 = conv_block(c2, 48, pool=False)\n",
    "\n",
    "    u3 = UpSampling2D((2, 2), interpolation=\"bilinear\")(x6)\n",
    "    c3 = Concatenate()([u3, x2])\n",
    "    x7 = conv_block(c3, 32, pool=False)\n",
    "\n",
    "    u4 = UpSampling2D((2, 2), interpolation=\"bilinear\")(x7)\n",
    "    c4 = Concatenate()([u4, x1])\n",
    "    x8 = conv_block(c4, 16, pool=False)\n",
    "\n",
    "    \"\"\" Output layer \"\"\"\n",
    "    output = Conv2D(num_classes, 1, padding=\"same\", activation=\"softmax\")(x8)\n",
    "\n",
    "    return Model(inputs, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea4356f-9e37-458d-b993-dc4484ef666d",
   "metadata": {},
   "source": [
    "## Funciones de carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b0745b3-069b-4840-a1a7-f3ffd89283ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_img_array(num_img, heigth, width, channels: int = 1) -> typ.Tuple[np.array, np.array]:\n",
    "    array_rsp = np.zeros((num_img, heigth, width, channels), dtype=np.float32)    \n",
    "    return array_rsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "614c03dc-85e6-46fb-a20a-bdb65657dbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_channel_raster(path_raster_tiff: str, channel: int = 1) -> np.array:\n",
    "    rsp = None\n",
    "    with rio.open(path_raster_tiff, \"r\") as rf:\n",
    "        rsp = rf.read(channel)\n",
    "    return rsp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e76c794-d403-416f-b953-e908c45c9a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_source_img(img_folder_path: str) -> np.array:\n",
    "    # Obtener la referencia a las bandas RGB + infrarrojo cercano\n",
    "    red_channel = glob.glob(f\"{img_folder_path}/B04.*\")[0]\n",
    "    green_channel = glob.glob(f\"{img_folder_path}/B03.*\")[0]\n",
    "    blue_channel = glob.glob(f\"{img_folder_path}/B02.*\")[0]\n",
    "    infrared_channel = glob.glob(f\"{img_folder_path}/B08.*\")[0]\n",
    "    \n",
    "    # Cargar las cuatro bandas\n",
    "    channels_list = [\n",
    "        red_channel, green_channel, blue_channel, infrared_channel\n",
    "    ]\n",
    "    raster_bands = [\n",
    "        load_channel_raster(r)\n",
    "        for r in channels_list\n",
    "    ]\n",
    "    \n",
    "    # Normalizar los canales\n",
    "    norm_data = lambda x: ((x - np.mean(x))/ np.std(x))\n",
    "                           \n",
    "    # Aplicar\n",
    "    norm_raster_bands = [\n",
    "        norm_data(raster_band)\n",
    "        for raster_band in raster_bands\n",
    "    ]\n",
    "            \n",
    "    # Construir el arreglo y retornar\n",
    "    return np.array(norm_raster_bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5bdec99-f9ce-495e-a3f7-df3793e60121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mask_img(mask_folder_path: str) -> np.array:\n",
    "    # Obtener la referencia de la máscara\n",
    "    mask_path = glob.glob(f\"{mask_folder_path}/labels.*\")[0]\n",
    "    \n",
    "    # Retornar la máscara\n",
    "    return load_channel_raster(mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49ca4644-acd8-42a5-b1a3-b1e2fc9a7290",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndvi(raster_array: np.array) -> np.array:\n",
    "    # Se toma como referencia el orden de las bandas en load_source_img()\n",
    "    # Las dimensiones aca son [bandas, altura, ancho]\n",
    "    # Formula: NDVI (Sentinel 2) = (B8 – B4) / (B8 + B4)\n",
    "    red_channel = raster_array[0, :, :]\n",
    "    infrared_channel = raster_array[-1, :, :]\n",
    "    \n",
    "    # Evitar divisiones por cero e inestabilidades\n",
    "    epsilon = 1e-8\n",
    "    return ((infrared_channel - red_channel) / ((infrared_channel + red_channel) + epsilon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0324404d-2b87-4081-9efd-a28b6b013a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_mask_path_folder(chip_id: str) -> str:\n",
    "    # Retorna la ruta con base en el chip\n",
    "    label_folder = f\"{DATA_BASE}/ref_landcovernet_v1_labels/ref_landcovernet_v1_labels_{chip_id}\"\n",
    "    return label_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1e97187-c471-414d-8c0f-4101dbded763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_mask_one_hot(raster_mask: np.array, classes: typ.List[int]) -> np.array:\n",
    "    # Retorna una máscara One Hot por cada clase\n",
    "    # Obtenerla en 2D solo con el primer canal\n",
    "    raster_mask_2d = raster_mask \n",
    "    masks = [\n",
    "        (raster_mask_2d == i).astype(np.uint16)\n",
    "        for i in classes\n",
    "    ]\n",
    "    \n",
    "    return np.array(masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a58376-7028-402b-b454-d96685abb846",
   "metadata": {},
   "source": [
    "## Cargar los datos de las imagenes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa38fb15-231e-460e-9e92-242b44e2c1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar JSON con las imagenes\n",
    "images_df = pd.read_json(f\"{DATA_BASE}/images_to_use.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42d75700-f807-497a-ac23-793b3733c3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determinar muestra\n",
    "sample_train = images_df.sample(frac=0.05, random_state=24)\n",
    "sample_train_np = sample_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "897be678-9c3b-40c2-815a-fafbc699127e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Muestras: 1509\n"
     ]
    }
   ],
   "source": [
    "samples_number = sample_train_np.shape[0]\n",
    "print(f\"Muestras: {samples_number}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc3794f0-f18b-484e-8400-75e5214f7067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir el arreglo\n",
    "X = create_img_array (\n",
    "    num_img = samples_number,\n",
    "    heigth = HEIGHT,\n",
    "    width = WIDTH,\n",
    "    channels = CHANNELS\n",
    ")\n",
    "\n",
    "Y = create_img_array (\n",
    "    num_img = samples_number,\n",
    "    heigth = HEIGHT,\n",
    "    width = WIDTH,  \n",
    "    channels = 7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc04b1bc-1c00-461b-bee0-785a2872f7ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43f2a6c38f38481abe7faed1db043d19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1509 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar la carga\n",
    "for row_id in tqdm(range(len(sample_train_np))):\n",
    "    row = sample_train_np[row_id]\n",
    "    chip_id = row[1]\n",
    "    source_path = row[2]\n",
    "    \n",
    "    # Cargar la imagen fuente\n",
    "    source_raster = load_source_img(source_path)\n",
    "    # Transformar con NDVI\n",
    "    # Descartar para la version V2 de U-Net\n",
    "    #source_raster = ndvi(source_raster)\n",
    "    \n",
    "    # Cargar la máscara\n",
    "    mask_folder_path = get_label_mask_path_folder(chip_id=chip_id)\n",
    "    mask_raster = load_mask_img(mask_folder_path)\n",
    "    mask_raster_classes = label_mask_one_hot(mask_raster, list(range(1,8)))\n",
    "    \n",
    "    # Almacenar\n",
    "    X[row_id] = rio_plot.reshape_as_image(source_raster)\n",
    "    Y[row_id] = rio_plot.reshape_as_image(mask_raster_classes)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0772b6dd-bf36-4621-b287-ba457d153c02",
   "metadata": {},
   "source": [
    "## Conjuntos de entrenamiento, validación, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd2ab930-7be8-440b-b5c3-37b086ad59e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuir el conjunto de entrenamiento en dos, train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Distribuir el conjunto de entrenamiento en dos, train y valid (validation)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ad390a-cca2-4ae4-8f12-067ee48d139e",
   "metadata": {},
   "source": [
    "## Instanciar el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc11d64-6d9a-4ef3-ba09-06818809947c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Versión del Labo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c358803-691c-43f1-afee-a62460b19b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-05 01:36:26.998853: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "input_img = Input((HEIGHT, WIDTH, 1), name='img_shape')\n",
    "model = get_unet(input_img, n_filters=16, dropout=0.05, batchnorm=True)\n",
    "model.compile(optimizer=Adam(), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b3a7d4a-0ebe-4cea-8266-7abaef18ea55",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(patience=10, verbose=1),\n",
    "    ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.00001, verbose=1),\n",
    "    ModelCheckpoint('model-ndvi.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "773d54d5-10a3-4151-a904-c4613f5b41e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "User settings:\n",
      "\n",
      "   KMP_AFFINITY=granularity=fine,verbose,compact,1,0\n",
      "   KMP_BLOCKTIME=0\n",
      "   KMP_DUPLICATE_LIB_OK=True\n",
      "   KMP_INIT_AT_FORK=FALSE\n",
      "   KMP_SETTINGS=1\n",
      "   OMP_NUM_THREADS=8\n",
      "\n",
      "Effective settings:\n",
      "\n",
      "   KMP_ABORT_DELAY=0\n",
      "   KMP_ADAPTIVE_LOCK_PROPS='1,1024'\n",
      "   KMP_ALIGN_ALLOC=64\n",
      "   KMP_ALL_THREADPRIVATE=128\n",
      "   KMP_ATOMIC_MODE=2\n",
      "   KMP_BLOCKTIME=0\n",
      "   KMP_CPUINFO_FILE: value is not defined\n",
      "   KMP_DETERMINISTIC_REDUCTION=false\n",
      "   KMP_DEVICE_THREAD_LIMIT=2147483647\n",
      "   KMP_DISP_NUM_BUFFERS=7\n",
      "   KMP_DUPLICATE_LIB_OK=true\n",
      "   KMP_ENABLE_TASK_THROTTLING=true\n",
      "   KMP_FORCE_REDUCTION: value is not defined\n",
      "   KMP_FOREIGN_THREADS_THREADPRIVATE=true\n",
      "   KMP_FORKJOIN_BARRIER='2,2'\n",
      "   KMP_FORKJOIN_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_GTID_MODE=3\n",
      "   KMP_HANDLE_SIGNALS=false\n",
      "   KMP_HOT_TEAMS_MAX_LEVEL=1\n",
      "   KMP_HOT_TEAMS_MODE=0\n",
      "   KMP_INIT_AT_FORK=true\n",
      "   KMP_LIBRARY=throughput\n",
      "   KMP_LOCK_KIND=queuing\n",
      "   KMP_MALLOC_POOL_INCR=1M\n",
      "   KMP_NUM_LOCKS_IN_BLOCK=1\n",
      "   KMP_PLAIN_BARRIER='2,2'\n",
      "   KMP_PLAIN_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_REDUCTION_BARRIER='1,1'\n",
      "   KMP_REDUCTION_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_SCHEDULE='static,balanced;guided,iterative'\n",
      "   KMP_SETTINGS=true\n",
      "   KMP_SPIN_BACKOFF_PARAMS='4096,100'\n",
      "   KMP_STACKOFFSET=64\n",
      "   KMP_STACKPAD=0\n",
      "   KMP_STACKSIZE=8M\n",
      "   KMP_STORAGE_MAP=false\n",
      "   KMP_TASKING=2\n",
      "   KMP_TASKLOOP_MIN_TASKS=0\n",
      "   KMP_TASK_STEALING_CONSTRAINT=1\n",
      "   KMP_TEAMS_THREAD_LIMIT=8\n",
      "   KMP_TOPOLOGY_METHOD=all\n",
      "   KMP_USE_YIELD=1\n",
      "   KMP_VERSION=false\n",
      "   KMP_WARNINGS=true\n",
      "   OMP_AFFINITY_FORMAT='OMP: pid %P tid %i thread %n bound to OS proc set {%A}'\n",
      "   OMP_ALLOCATOR=omp_default_mem_alloc\n",
      "   OMP_CANCELLATION=false\n",
      "   OMP_DEFAULT_DEVICE=0\n",
      "   OMP_DISPLAY_AFFINITY=false\n",
      "   OMP_DISPLAY_ENV=false\n",
      "   OMP_DYNAMIC=false\n",
      "   OMP_MAX_ACTIVE_LEVELS=1\n",
      "   OMP_MAX_TASK_PRIORITY=0\n",
      "   OMP_NESTED: deprecated; max-active-levels-var=1\n",
      "   OMP_NUM_THREADS='8'\n",
      "   OMP_PLACES: value is not defined\n",
      "   OMP_PROC_BIND='intel'\n",
      "   OMP_SCHEDULE='static'\n",
      "   OMP_STACKSIZE=8M\n",
      "   OMP_TARGET_OFFLOAD=DEFAULT\n",
      "   OMP_THREAD_LIMIT=2147483647\n",
      "   OMP_WAIT_POLICY=PASSIVE\n",
      "   KMP_AFFINITY='verbose,warnings,respect,granularity=fine,compact,1,0'\n",
      "\n",
      "OMP: Info #211: KMP_AFFINITY: decoding x2APIC ids.\n",
      "OMP: Info #209: KMP_AFFINITY: Affinity capable, using global cpuid leaf 11 info\n",
      "OMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0-7\n",
      "OMP: Info #156: KMP_AFFINITY: 8 available OS procs\n",
      "OMP: Info #157: KMP_AFFINITY: Uniform topology\n",
      "OMP: Info #179: KMP_AFFINITY: 1 packages x 4 cores/pkg x 2 threads/core (4 total cores)\n",
      "OMP: Info #213: KMP_AFFINITY: OS proc to physical thread map:\n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 0 maps to package 0 core 0 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 4 maps to package 0 core 0 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 1 maps to package 0 core 1 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 5 maps to package 0 core 1 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 2 maps to package 0 core 2 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 6 maps to package 0 core 2 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 3 maps to package 0 core 3 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 7 maps to package 0 core 3 thread 1 \n",
      "OMP: Info #249: KMP_AFFINITY: pid 3827 tid 3944 thread 0 bound to OS proc set 0\n",
      "OMP: Info #249: KMP_AFFINITY: pid 3827 tid 4049 thread 1 bound to OS proc set 1\n",
      "OMP: Info #249: KMP_AFFINITY: pid 3827 tid 4050 thread 2 bound to OS proc set 2\n",
      "OMP: Info #249: KMP_AFFINITY: pid 3827 tid 4052 thread 4 bound to OS proc set 4\n",
      "OMP: Info #249: KMP_AFFINITY: pid 3827 tid 4054 thread 6 bound to OS proc set 6\n",
      "OMP: Info #249: KMP_AFFINITY: pid 3827 tid 4053 thread 5 bound to OS proc set 5\n",
      "OMP: Info #249: KMP_AFFINITY: pid 3827 tid 4051 thread 3 bound to OS proc set 3\n",
      "OMP: Info #249: KMP_AFFINITY: pid 3827 tid 4055 thread 7 bound to OS proc set 7\n",
      "OMP: Info #249: KMP_AFFINITY: pid 3827 tid 3943 thread 8 bound to OS proc set 0\n",
      "OMP: Info #249: KMP_AFFINITY: pid 3827 tid 4057 thread 10 bound to OS proc set 2\n",
      "OMP: Info #249: KMP_AFFINITY: pid 3827 tid 4058 thread 11 bound to OS proc set 3\n",
      "OMP: Info #249: KMP_AFFINITY: pid 3827 tid 4056 thread 9 bound to OS proc set 1\n",
      "OMP: Info #249: KMP_AFFINITY: pid 3827 tid 4059 thread 12 bound to OS proc set 4\n",
      "OMP: Info #249: KMP_AFFINITY: pid 3827 tid 4060 thread 13 bound to OS proc set 5\n",
      "OMP: Info #249: KMP_AFFINITY: pid 3827 tid 4061 thread 14 bound to OS proc set 6\n",
      "OMP: Info #249: KMP_AFFINITY: pid 3827 tid 4062 thread 15 bound to OS proc set 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - ETA: 0s - loss: -1.8363 - accuracy: 0.0105\n",
      "Epoch 00001: val_loss improved from inf to -1.30918, saving model to model-ndvi.h5\n",
      "39/39 [==============================] - 98s 2s/step - loss: -1.8363 - accuracy: 0.0105 - val_loss: -1.3092 - val_accuracy: 0.0151 - lr: 0.0010\n",
      "Epoch 2/5\n",
      "39/39 [==============================] - ETA: 0s - loss: -4.9283 - accuracy: 0.0123\n",
      "Epoch 00002: val_loss improved from -1.30918 to -2.08403, saving model to model-ndvi.h5\n",
      "39/39 [==============================] - 95s 2s/step - loss: -4.9283 - accuracy: 0.0123 - val_loss: -2.0840 - val_accuracy: 0.0151 - lr: 0.0010\n",
      "Epoch 3/5\n",
      "39/39 [==============================] - ETA: 0s - loss: -6.5616 - accuracy: 0.0124\n",
      "Epoch 00003: val_loss improved from -2.08403 to -3.95525, saving model to model-ndvi.h5\n",
      "39/39 [==============================] - 95s 2s/step - loss: -6.5616 - accuracy: 0.0124 - val_loss: -3.9553 - val_accuracy: 0.0151 - lr: 0.0010\n",
      "Epoch 4/5\n",
      "39/39 [==============================] - ETA: 0s - loss: -8.2833 - accuracy: 0.0124\n",
      "Epoch 00004: val_loss improved from -3.95525 to -6.38723, saving model to model-ndvi.h5\n",
      "39/39 [==============================] - 95s 2s/step - loss: -8.2833 - accuracy: 0.0124 - val_loss: -6.3872 - val_accuracy: 0.0151 - lr: 0.0010\n",
      "Epoch 5/5\n",
      "39/39 [==============================] - ETA: 0s - loss: -10.1893 - accuracy: 0.0124\n",
      "Epoch 00005: val_loss improved from -6.38723 to -9.03810, saving model to model-ndvi.h5\n",
      "39/39 [==============================] - 95s 2s/step - loss: -10.1893 - accuracy: 0.0124 - val_loss: -9.0381 - val_accuracy: 0.0151 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "results = model.fit(X_train, y_train, batch_size=32, epochs=5, callbacks=callbacks,\\\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2f2272-94cd-40e6-a7dd-d130505a09ee",
   "metadata": {},
   "source": [
    "### Versión V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf64d3ff-e981-4a39-8a65-d9271a4b0703",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-05 02:47:00.243264: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "model_v2_shape = (HEIGHT, WIDTH, 4)\n",
    "model_v2_classes = 7\n",
    "model = build_unet(model_v2_shape, model_v2_classes)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=tf.keras.optimizers.Adam(1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "312601bd-8a76-4adc-a216-8f31e266145a",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "        ModelCheckpoint(\"model.h5\", verbose=1, save_best_model=True),\n",
    "        ReduceLROnPlateau(monitor=\"val_loss\", patience=3, factor=0.1, verbose=1, min_lr=1e-6),\n",
    "        EarlyStopping(monitor=\"val_loss\", patience=5, verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02fa5aad-5d52-4c08-9250-f4b926dd2368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "User settings:\n",
      "\n",
      "   KMP_AFFINITY=granularity=fine,verbose,compact,1,0\n",
      "   KMP_BLOCKTIME=0\n",
      "   KMP_DUPLICATE_LIB_OK=True\n",
      "   KMP_INIT_AT_FORK=FALSE\n",
      "   KMP_SETTINGS=1\n",
      "   OMP_NUM_THREADS=8\n",
      "\n",
      "Effective settings:\n",
      "\n",
      "   KMP_ABORT_DELAY=0\n",
      "   KMP_ADAPTIVE_LOCK_PROPS='1,1024'\n",
      "   KMP_ALIGN_ALLOC=64\n",
      "   KMP_ALL_THREADPRIVATE=128\n",
      "   KMP_ATOMIC_MODE=2\n",
      "   KMP_BLOCKTIME=0\n",
      "   KMP_CPUINFO_FILE: value is not defined\n",
      "   KMP_DETERMINISTIC_REDUCTION=false\n",
      "   KMP_DEVICE_THREAD_LIMIT=2147483647\n",
      "   KMP_DISP_NUM_BUFFERS=7\n",
      "   KMP_DUPLICATE_LIB_OK=true\n",
      "   KMP_ENABLE_TASK_THROTTLING=true\n",
      "   KMP_FORCE_REDUCTION: value is not defined\n",
      "   KMP_FOREIGN_THREADS_THREADPRIVATE=true\n",
      "   KMP_FORKJOIN_BARRIER='2,2'\n",
      "   KMP_FORKJOIN_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_GTID_MODE=3\n",
      "   KMP_HANDLE_SIGNALS=false\n",
      "   KMP_HOT_TEAMS_MAX_LEVEL=1\n",
      "   KMP_HOT_TEAMS_MODE=0\n",
      "   KMP_INIT_AT_FORK=true\n",
      "   KMP_LIBRARY=throughput\n",
      "   KMP_LOCK_KIND=queuing\n",
      "   KMP_MALLOC_POOL_INCR=1M\n",
      "   KMP_NUM_LOCKS_IN_BLOCK=1\n",
      "   KMP_PLAIN_BARRIER='2,2'\n",
      "   KMP_PLAIN_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_REDUCTION_BARRIER='1,1'\n",
      "   KMP_REDUCTION_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_SCHEDULE='static,balanced;guided,iterative'\n",
      "   KMP_SETTINGS=true\n",
      "   KMP_SPIN_BACKOFF_PARAMS='4096,100'\n",
      "   KMP_STACKOFFSET=64\n",
      "   KMP_STACKPAD=0\n",
      "   KMP_STACKSIZE=8M\n",
      "   KMP_STORAGE_MAP=false\n",
      "   KMP_TASKING=2\n",
      "   KMP_TASKLOOP_MIN_TASKS=0\n",
      "   KMP_TASK_STEALING_CONSTRAINT=1\n",
      "   KMP_TEAMS_THREAD_LIMIT=8\n",
      "   KMP_TOPOLOGY_METHOD=all\n",
      "   KMP_USE_YIELD=1\n",
      "   KMP_VERSION=false\n",
      "   KMP_WARNINGS=true\n",
      "   OMP_AFFINITY_FORMAT='OMP: pid %P tid %i thread %n bound to OS proc set {%A}'\n",
      "   OMP_ALLOCATOR=omp_default_mem_alloc\n",
      "   OMP_CANCELLATION=false\n",
      "   OMP_DEFAULT_DEVICE=0\n",
      "   OMP_DISPLAY_AFFINITY=false\n",
      "   OMP_DISPLAY_ENV=false\n",
      "   OMP_DYNAMIC=false\n",
      "   OMP_MAX_ACTIVE_LEVELS=1\n",
      "   OMP_MAX_TASK_PRIORITY=0\n",
      "   OMP_NESTED: deprecated; max-active-levels-var=1\n",
      "   OMP_NUM_THREADS='8'\n",
      "   OMP_PLACES: value is not defined\n",
      "   OMP_PROC_BIND='intel'\n",
      "   OMP_SCHEDULE='static'\n",
      "   OMP_STACKSIZE=8M\n",
      "   OMP_TARGET_OFFLOAD=DEFAULT\n",
      "   OMP_THREAD_LIMIT=2147483647\n",
      "   OMP_WAIT_POLICY=PASSIVE\n",
      "   KMP_AFFINITY='verbose,warnings,respect,granularity=fine,compact,1,0'\n",
      "\n",
      "OMP: Info #211: KMP_AFFINITY: decoding x2APIC ids.\n",
      "OMP: Info #209: KMP_AFFINITY: Affinity capable, using global cpuid leaf 11 info\n",
      "OMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0-7\n",
      "OMP: Info #156: KMP_AFFINITY: 8 available OS procs\n",
      "OMP: Info #157: KMP_AFFINITY: Uniform topology\n",
      "OMP: Info #179: KMP_AFFINITY: 1 packages x 4 cores/pkg x 2 threads/core (4 total cores)\n",
      "OMP: Info #213: KMP_AFFINITY: OS proc to physical thread map:\n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 0 maps to package 0 core 0 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 4 maps to package 0 core 0 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 1 maps to package 0 core 1 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 5 maps to package 0 core 1 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 2 maps to package 0 core 2 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 6 maps to package 0 core 2 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 3 maps to package 0 core 3 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 7 maps to package 0 core 3 thread 1 \n",
      "OMP: Info #249: KMP_AFFINITY: pid 5249 tid 5299 thread 0 bound to OS proc set 0\n",
      "OMP: Info #249: KMP_AFFINITY: pid 5249 tid 5318 thread 1 bound to OS proc set 1\n",
      "OMP: Info #249: KMP_AFFINITY: pid 5249 tid 5319 thread 2 bound to OS proc set 2\n",
      "OMP: Info #249: KMP_AFFINITY: pid 5249 tid 5320 thread 3 bound to OS proc set 3\n",
      "OMP: Info #249: KMP_AFFINITY: pid 5249 tid 5321 thread 4 bound to OS proc set 4\n",
      "OMP: Info #249: KMP_AFFINITY: pid 5249 tid 5322 thread 5 bound to OS proc set 5\n",
      "OMP: Info #249: KMP_AFFINITY: pid 5249 tid 5323 thread 6 bound to OS proc set 6\n",
      "OMP: Info #249: KMP_AFFINITY: pid 5249 tid 5324 thread 7 bound to OS proc set 7\n",
      "OMP: Info #249: KMP_AFFINITY: pid 5249 tid 5298 thread 8 bound to OS proc set 0\n",
      "OMP: Info #249: KMP_AFFINITY: pid 5249 tid 5325 thread 9 bound to OS proc set 1\n",
      "OMP: Info #249: KMP_AFFINITY: pid 5249 tid 5326 thread 10 bound to OS proc set 2\n",
      "OMP: Info #249: KMP_AFFINITY: pid 5249 tid 5327 thread 11 bound to OS proc set 3\n",
      "OMP: Info #249: KMP_AFFINITY: pid 5249 tid 5328 thread 12 bound to OS proc set 4\n",
      "OMP: Info #249: KMP_AFFINITY: pid 5249 tid 5329 thread 13 bound to OS proc set 5\n",
      "OMP: Info #249: KMP_AFFINITY: pid 5249 tid 5330 thread 14 bound to OS proc set 6\n",
      "OMP: Info #249: KMP_AFFINITY: pid 5249 tid 5331 thread 15 bound to OS proc set 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - ETA: 0s - loss: 2.1882 - accuracy: 0.0931\n",
      "Epoch 00001: saving model to model.h5\n",
      "39/39 [==============================] - 129s 3s/step - loss: 2.1882 - accuracy: 0.0931 - val_loss: 1.9396 - val_accuracy: 0.1821 - lr: 1.0000e-04\n",
      "Epoch 2/5\n",
      "39/39 [==============================] - ETA: 0s - loss: 1.9700 - accuracy: 0.1613\n",
      "Epoch 00002: saving model to model.h5\n",
      "39/39 [==============================] - 126s 3s/step - loss: 1.9700 - accuracy: 0.1613 - val_loss: 1.9380 - val_accuracy: 0.1822 - lr: 1.0000e-04\n",
      "Epoch 3/5\n",
      "39/39 [==============================] - ETA: 0s - loss: 1.9070 - accuracy: 0.1890\n",
      "Epoch 00003: saving model to model.h5\n",
      "39/39 [==============================] - 126s 3s/step - loss: 1.9070 - accuracy: 0.1890 - val_loss: 1.9381 - val_accuracy: 0.1819 - lr: 1.0000e-04\n",
      "Epoch 4/5\n",
      "39/39 [==============================] - ETA: 0s - loss: 1.8665 - accuracy: 0.2052\n",
      "Epoch 00004: saving model to model.h5\n",
      "39/39 [==============================] - 126s 3s/step - loss: 1.8665 - accuracy: 0.2052 - val_loss: 1.9324 - val_accuracy: 0.1806 - lr: 1.0000e-04\n",
      "Epoch 5/5\n",
      "39/39 [==============================] - ETA: 0s - loss: 1.8412 - accuracy: 0.2236\n",
      "Epoch 00005: saving model to model.h5\n",
      "39/39 [==============================] - 126s 3s/step - loss: 1.8412 - accuracy: 0.2236 - val_loss: 1.9271 - val_accuracy: 0.1816 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "results = model.fit(X_train, y_train, batch_size=32, epochs=5, callbacks=callbacks,\\\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20516df0-9afa-496e-a860-22aca566a19e",
   "metadata": {},
   "source": [
    "# Next section"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

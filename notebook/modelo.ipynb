{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b243b22-1b39-448d-9a9c-ca6e40ae53d1",
   "metadata": {},
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c988bc-5503-4764-8896-40fceb43ca5d",
   "metadata": {},
   "source": [
    "Iteración rápida con un modelo de U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "835511b9-f366-43e0-8a78-50f5f5232d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from matplotlib import colors\n",
    "from skimage import exposure\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# =================|\n",
    "# Tensorflow\n",
    "# =================\n",
    "\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout, MaxPool2D, UpSampling2D, Concatenate\n",
    "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n",
    "from keras.layers.merge import concatenate, add\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "from scipy import ndimage\n",
    "\n",
    "#=========================\n",
    "\n",
    "import rasterio as rio\n",
    "import rasterio.plot as rio_plot\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import json\n",
    "import typing as typ\n",
    "import math\n",
    "import time\n",
    "\n",
    "# Semilla pseudoaleatoria\n",
    "np.random.seed(24)\n",
    "\n",
    "# Tamaño de las figuras\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "\n",
    "# Ruta base de la carpeta de datos\n",
    "DATA_BASE = \"/home/ggonzr_cloud/deeplearn/data\"\n",
    "\n",
    "# Imagen\n",
    "HEIGHT = 256\n",
    "WIDTH = 256\n",
    "CHANNELS = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e724c7-4077-4df4-8fbb-d817599ee15e",
   "metadata": {},
   "source": [
    "## Definición del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77e9594-efe5-4b3a-b1a9-e92dbd6d813f",
   "metadata": {},
   "source": [
    "### Versión V2\n",
    "\n",
    "Link: https://github.com/nikhilroxtomar/Multiclass-Segmentation-in-Unet/blob/master/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c692602-90c6-4992-a9b4-73e6fa8f9574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(inputs, filters, pool=True):\n",
    "    x = Conv2D(filters, 3, padding=\"same\")(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(filters, 3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    if pool == True:\n",
    "        p = MaxPool2D((2, 2))(x)\n",
    "        return x, p\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def build_unet(shape, num_classes):\n",
    "    inputs = Input(shape)\n",
    "\n",
    "    \"\"\" Encoder \"\"\"\n",
    "    x1, p1 = conv_block(inputs, 16, pool=True)\n",
    "    x2, p2 = conv_block(p1, 32, pool=True)\n",
    "    x3, p3 = conv_block(p2, 48, pool=True)\n",
    "    x4, p4 = conv_block(p3, 64, pool=True)\n",
    "\n",
    "    \"\"\" Bridge \"\"\"\n",
    "    b1 = conv_block(p4, 128, pool=False)\n",
    "\n",
    "    \"\"\" Decoder \"\"\"\n",
    "    u1 = UpSampling2D((2, 2), interpolation=\"bilinear\")(b1)\n",
    "    c1 = Concatenate()([u1, x4])\n",
    "    x5 = conv_block(c1, 64, pool=False)\n",
    "\n",
    "    u2 = UpSampling2D((2, 2), interpolation=\"bilinear\")(x5)\n",
    "    c2 = Concatenate()([u2, x3])\n",
    "    x6 = conv_block(c2, 48, pool=False)\n",
    "\n",
    "    u3 = UpSampling2D((2, 2), interpolation=\"bilinear\")(x6)\n",
    "    c3 = Concatenate()([u3, x2])\n",
    "    x7 = conv_block(c3, 32, pool=False)\n",
    "\n",
    "    u4 = UpSampling2D((2, 2), interpolation=\"bilinear\")(x7)\n",
    "    c4 = Concatenate()([u4, x1])\n",
    "    x8 = conv_block(c4, 16, pool=False)\n",
    "\n",
    "    \"\"\" Output layer \"\"\"\n",
    "    output = Conv2D(num_classes, 1, padding=\"same\", activation=\"softmax\")(x8)\n",
    "\n",
    "    return Model(inputs, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea4356f-9e37-458d-b993-dc4484ef666d",
   "metadata": {},
   "source": [
    "## Funciones de carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b0745b3-069b-4840-a1a7-f3ffd89283ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_img_array(num_img, heigth, width, channels: int = 1) -> typ.Tuple[np.array, np.array]:\n",
    "    array_rsp = np.zeros((num_img, heigth, width, channels), dtype=np.float32)    \n",
    "    return array_rsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "614c03dc-85e6-46fb-a20a-bdb65657dbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_channel_raster(path_raster_tiff: str, channel: int = 1) -> np.array:\n",
    "    rsp = None\n",
    "    with rio.open(path_raster_tiff, \"r\") as rf:\n",
    "        rsp = rf.read(channel)\n",
    "    return rsp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e76c794-d403-416f-b953-e908c45c9a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_source_img(img_folder_path: str) -> np.array:\n",
    "    # Obtener la referencia a las bandas\n",
    "    # Un poco excesivo, pero por si las moscas, especificaremos el patron de cada imagen a mano\n",
    "    aerosol_1 = glob.glob(f\"{img_folder_path}/B01.*\")[0]\n",
    "    azul_2 = glob.glob(f\"{img_folder_path}/B02.*\")[0]\n",
    "    verde_3 = glob.glob(f\"{img_folder_path}/B03.*\")[0]\n",
    "    rojo_4 = glob.glob(f\"{img_folder_path}/B04.*\")[0]\n",
    "    rojo_frontera_1_5 = glob.glob(f\"{img_folder_path}/B05.*\")[0]\n",
    "    rojo_frontera_2_6 = glob.glob(f\"{img_folder_path}/B06.*\")[0]\n",
    "    rojo_frontera_3_7 = glob.glob(f\"{img_folder_path}/B07.*\")[0]\n",
    "    infrarrojo_8 = glob.glob(f\"{img_folder_path}/B08.*\")[0]\n",
    "    infrarrojo_8A_9 = glob.glob(f\"{img_folder_path}/B8A.*\")[0]\n",
    "    vapor_agua_9_10 = glob.glob(f\"{img_folder_path}/B09.*\")[0]\n",
    "    onda_corta_1_11 = glob.glob(f\"{img_folder_path}/B11.*\")[0]\n",
    "    onda_corta_2_12 = glob.glob(f\"{img_folder_path}/B12.*\")[0]\n",
    "    \n",
    "    # Cargar las cuatro bandas\n",
    "    channels_list = [\n",
    "        aerosol_1,\n",
    "        azul_2,\n",
    "        verde_3,\n",
    "        rojo_4,\n",
    "        rojo_frontera_1_5,\n",
    "        rojo_frontera_2_6,\n",
    "        rojo_frontera_3_7,\n",
    "        infrarrojo_8,\n",
    "        infrarrojo_8A_9,\n",
    "        vapor_agua_9_10,\n",
    "        onda_corta_1_11,\n",
    "        onda_corta_2_12\n",
    "    ]\n",
    "    \n",
    "    raster_bands = [\n",
    "        load_channel_raster(r)\n",
    "        for r in channels_list\n",
    "    ]\n",
    "    \n",
    "    # Evitar los NaN, +Infinite, -Infinite\n",
    "    raster_bands_clean = [\n",
    "        np.nan_to_num(r, nan=0, posinf=0, neginf=0)\n",
    "        for r in raster_bands\n",
    "    ]\n",
    "    \n",
    "    # Normalizar los canales\n",
    "    norm_data = lambda x: ((x - np.mean(x))/ np.std(x))\n",
    "                           \n",
    "    # Aplicar\n",
    "    norm_raster_bands = [\n",
    "        norm_data(raster_band)\n",
    "        for raster_band in raster_bands_clean\n",
    "    ]\n",
    "            \n",
    "    # Construir el arreglo y retornar\n",
    "    return np.array(norm_raster_bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5bdec99-f9ce-495e-a3f7-df3793e60121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mask_img(mask_folder_path: str) -> np.array:\n",
    "    # Obtener la referencia de la máscara\n",
    "    mask_path = glob.glob(f\"{mask_folder_path}/labels.*\")[0]\n",
    "    \n",
    "    # Retornar la máscara\n",
    "    loaded_channel = load_channel_raster(mask_path)\n",
    "    loaded_channel_clean = np.nan_to_num(loaded_channel, nan=0, posinf=0, neginf=0)\n",
    "    \n",
    "    return loaded_channel_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49ca4644-acd8-42a5-b1a3-b1e2fc9a7290",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndvi(raster_array: np.array) -> np.array:    \n",
    "    # Las dimensiones aca son [bandas, altura, ancho]\n",
    "    # Formula: NDVI (Sentinel 2) = (B8 – B4) / (B8 + B4)\n",
    "    # Se toma con base en la modificacion con 12 bandas    \n",
    "    # Mayor informacion, por favor ver definicion del metodo: load_source_img\n",
    "    red_channel = raster_array[3, :, :]\n",
    "    infrared_channel = raster_array[7, :, :]\n",
    "    \n",
    "    # Evitar divisiones por cero e inestabilidades\n",
    "    epsilon = 1e-8\n",
    "    return ((infrared_channel - red_channel) / ((infrared_channel + red_channel) + epsilon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2337ea7d-06da-4524-8280-a9e0265a117c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bsi(raster_array: np.array) -> np.array:    \n",
    "    # Las dimensiones aca son [bandas, altura, ancho]    \n",
    "    # Se toma con base en la modificacion con 12 bandas    \n",
    "    # Mayor informacion, por favor ver definicion del metodo: load_source_img\n",
    "    # BSI (Sentinel 2) = (B11 + B4) – (B8 + B2) / (B11 + B4) + (B8 + B2)\n",
    "    \n",
    "    swir_1_11 = raster_array[10, :, :]\n",
    "    rojo_4 = raster_array[3, :, :]\n",
    "    infrarrojo_8 = raster_array[7, :, :]\n",
    "    azul_2 = raster_array[1, :, :]\n",
    "    \n",
    "    # Evitar divisiones por cero e inestabilidades\n",
    "    epsilon = 1e-8\n",
    "    \n",
    "    # SWIR <-> ROJO\n",
    "    swir_rojo = swir_1_11 + rojo_4\n",
    "    # NIR <-> AZUL\n",
    "    nir_azul = infrarrojo_8 + azul_2\n",
    "    \n",
    "    # Retornar\n",
    "    return (swir_rojo - nir_azul) / (swir_rojo + nir_azul + epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "344c7b5f-7c08-44e6-bee4-632cb2bc8ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndmi(raster_array: np.array) -> np.array:    \n",
    "    # Las dimensiones aca son [bandas, altura, ancho]    \n",
    "    # Se toma con base en la modificacion con 12 bandas    \n",
    "    # Mayor informacion, por favor ver definicion del metodo: load_source_img\n",
    "    # NDMI (Sentinel 2) = (B8 – B11) / (B8 + B11)\n",
    "    swir_1_11 = raster_array[10, :, :]\n",
    "    infrarrojo_8 = raster_array[7, :, :]\n",
    "    \n",
    "    # Evitar divisiones por cero e inestabilidades\n",
    "    epsilon = 1e-8\n",
    "    \n",
    "    return (infrarrojo_8 - swir_1_11) / (infrarrojo_8 + swir_1_11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0324404d-2b87-4081-9efd-a28b6b013a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_mask_path_folder(chip_id: str) -> str:\n",
    "    # Retorna la ruta con base en el chip\n",
    "    label_folder = f\"{DATA_BASE}/ref_landcovernet_v1_labels/ref_landcovernet_v1_labels_{chip_id}\"\n",
    "    return label_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1e97187-c471-414d-8c0f-4101dbded763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_mask_one_hot(raster_mask: np.array, classes: typ.List[int]) -> np.array:\n",
    "    # Retorna una máscara One Hot por cada clase\n",
    "    # Obtenerla en 2D solo con el primer canal\n",
    "    raster_mask_2d = raster_mask \n",
    "    masks = [\n",
    "        (raster_mask_2d == i).astype(np.uint16)\n",
    "        for i in classes\n",
    "    ]\n",
    "    \n",
    "    return np.array(masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d075389-2808-448f-b2e2-17b8a8396336",
   "metadata": {},
   "source": [
    "## Secuenciadores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5475451d-002c-460c-84e6-022f3f9ca4e9",
   "metadata": {},
   "source": [
    "Para apoyarnos rápidamente en la definición del secuenciador, vamos a apoyarnos de las funciones anteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac931f10-cc48-412e-95c3-3aa6228d2f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndexSequence(Sequence):\n",
    "    # x_sample_path: Arreglo con el contenido de las rutas e ID\n",
    "    # Administra los batch de trabajo.    \n",
    "    def __init__(self, x_sample_path: np.array, batch_size: int = 32):\n",
    "        self.x_sample_path = x_sample_path\n",
    "        self.batch_size = batch_size\n",
    "        self.classes = list(range(1,8))\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return math.ceil(self.x_sample_path.shape[0] / self.batch_size)\n",
    "    \n",
    "    \n",
    "    def load_img_index(self, source_path):\n",
    "        # Cargar el raster inicial -> [canal, alto, ancho]\n",
    "        source_raster = load_source_img(source_path)\n",
    "        \n",
    "        # Transformar la imagen\n",
    "        ndvi_transformed = ndvi(source_raster)\n",
    "        bsi_transformed = bsi(source_raster)\n",
    "        ndmi_transformed = ndmi(source_raster)        \n",
    "        \n",
    "        # Empaquetar y retornar\n",
    "        index_array = np.array([\n",
    "            ndvi_transformed,\n",
    "            bsi_transformed,\n",
    "            ndmi_transformed\n",
    "        ])\n",
    "        \n",
    "        return rio_plot.reshape_as_image(index_array)\n",
    "    \n",
    "    \n",
    "    def load_img_mask(self, chip_id):\n",
    "        # Cargar la máscara inicial -> [clase, alto, ancho]\n",
    "        mask_folder_path = get_label_mask_path_folder(chip_id=chip_id)\n",
    "        mask_raster = load_mask_img(mask_folder_path)\n",
    "        \n",
    "        # Sobre las clases\n",
    "        mask_raster_classes = label_mask_one_hot(mask_raster, self.classes)        \n",
    "        \n",
    "        return rio_plot.reshape_as_image(mask_raster_classes)\n",
    "                \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Obtener el batch de datos para cargar\n",
    "        batch_x = self.x_sample_path[idx * self.batch_size:(idx + 1) *\n",
    "        self.batch_size]\n",
    "        \n",
    "        # Arreglo de datos para imagenes\n",
    "        source_images = np.array([\n",
    "            self.load_img_index(row_data[2])\n",
    "            for row_data in batch_x\n",
    "        ])\n",
    "        \n",
    "        # Arreglo de datos con las máscaras\n",
    "        mask_images = np.array([\n",
    "            self.load_img_mask(row_data[1])\n",
    "            for row_data in batch_x\n",
    "        ])\n",
    "\n",
    "        return source_images, mask_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a58376-7028-402b-b454-d96685abb846",
   "metadata": {},
   "source": [
    "## Cargar los datos de las imagenes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa38fb15-231e-460e-9e92-242b44e2c1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar JSON con las imagenes\n",
    "images_df = pd.read_json(f\"{DATA_BASE}/images_to_use.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42d75700-f807-497a-ac23-793b3733c3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determinar muestra\n",
    "SAMPLE_SIZE = 0.25\n",
    "sample_train = images_df.sample(frac=SAMPLE_SIZE, random_state=24)\n",
    "sample_train_np = sample_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "897be678-9c3b-40c2-815a-fafbc699127e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Muestras: 7544\n"
     ]
    }
   ],
   "source": [
    "samples_number = sample_train_np.shape[0]\n",
    "print(f\"Muestras: {samples_number}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df16617-c577-4bbb-ae42-1cdbf36b2307",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Carga completa de las bandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc3794f0-f18b-484e-8400-75e5214f7067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir el arreglo\n",
    "X = create_img_array (\n",
    "    num_img = samples_number,\n",
    "    heigth = HEIGHT,\n",
    "    width = WIDTH,\n",
    "    channels = 12\n",
    ")\n",
    "\n",
    "Y = create_img_array (\n",
    "    num_img = samples_number,\n",
    "    heigth = HEIGHT,\n",
    "    width = WIDTH,  \n",
    "    channels = 7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc04b1bc-1c00-461b-bee0-785a2872f7ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3de98061223b4286aea0782741132d22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30178 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ejecutar la carga\n",
    "for row_id in tqdm(range(len(sample_train_np))):\n",
    "    row = sample_train_np[row_id]\n",
    "    chip_id = row[1]\n",
    "    source_path = row[2]\n",
    "    \n",
    "    # Cargar la imagen fuente\n",
    "    source_raster = load_source_img(source_path)\n",
    "    \n",
    "    # Transformar con NDVI\n",
    "    # Descartar para la version V2 de U-Net\n",
    "    #source_raster = ndvi(source_raster)\n",
    "    \n",
    "    # Cargar la máscara\n",
    "    mask_folder_path = get_label_mask_path_folder(chip_id=chip_id)\n",
    "    mask_raster = load_mask_img(mask_folder_path)\n",
    "    mask_raster_classes = label_mask_one_hot(mask_raster, list(range(1,8)))\n",
    "    \n",
    "    # A este punto tenemos dimensiones\n",
    "    # Fuente (source) -> [canal, alto, ancho] -> [12, 256, 256]\n",
    "    # Máscara -> [clase, alto, ancho] -> [7, 256, 256]\n",
    "    \n",
    "    # Aplicar transformaciones si son necesarias\n",
    "    # Cambian el orden de las dimensiones\n",
    "    # [alto, ancho, canal/clase] -> Por ejemplo: [256, 256, 12]\n",
    "    \n",
    "    # Almacenar    \n",
    "    X[row_id] = rio_plot.reshape_as_image(source_raster)\n",
    "    Y[row_id] = rio_plot.reshape_as_image(mask_raster_classes)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0772b6dd-bf36-4621-b287-ba457d153c02",
   "metadata": {},
   "source": [
    "## Conjuntos de entrenamiento, validación, test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a950b00-5867-443f-90ed-aa2d6ba6d88b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Por medio de arreglos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd2ab930-7be8-440b-b5c3-37b086ad59e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuir el conjunto de entrenamiento en dos, train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Distribuir el conjunto de entrenamiento en dos, train y valid (validation)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d4d51c-0da0-40f3-a1ad-2d726a941cd0",
   "metadata": {},
   "source": [
    "### Por medio de secuenciadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44835796-745e-44d4-b796-72a840d86df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuir la ruta de las imagenes en los conjuntos apropiados\n",
    "X_seq_train, X_seq_test = train_test_split(sample_train_np, test_size=0.2, random_state=42)\n",
    "# Validacion\n",
    "X_seq_train, X_seq_val = train_test_split(X_seq_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49fa4c75-12ed-4fc9-912d-3e09cbd3cc41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>chip_id</th>\n",
       "      <th>image_folder_path</th>\n",
       "      <th>cloud_mask_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33PWQ_13_20180504</td>\n",
       "      <td>33PWQ_13</td>\n",
       "      <td>/home/ggonzr_cloud/deeplearn/data/ref_landcove...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35NRD_15_20180113</td>\n",
       "      <td>35NRD_15</td>\n",
       "      <td>/home/ggonzr_cloud/deeplearn/data/ref_landcove...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31PGR_26_20181117</td>\n",
       "      <td>31PGR_26</td>\n",
       "      <td>/home/ggonzr_cloud/deeplearn/data/ref_landcove...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34LHJ_20_20180620</td>\n",
       "      <td>34LHJ_20</td>\n",
       "      <td>/home/ggonzr_cloud/deeplearn/data/ref_landcove...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32PPA_20_20180410</td>\n",
       "      <td>32PPA_20</td>\n",
       "      <td>/home/ggonzr_cloud/deeplearn/data/ref_landcove...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>34NBP_29_20180513</td>\n",
       "      <td>34NBP_29</td>\n",
       "      <td>/home/ggonzr_cloud/deeplearn/data/ref_landcove...</td>\n",
       "      <td>0.000122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1505</th>\n",
       "      <td>33KXV_05_20180924</td>\n",
       "      <td>33KXV_05</td>\n",
       "      <td>/home/ggonzr_cloud/deeplearn/data/ref_landcove...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1506</th>\n",
       "      <td>34JBL_26_20180817</td>\n",
       "      <td>34JBL_26</td>\n",
       "      <td>/home/ggonzr_cloud/deeplearn/data/ref_landcove...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507</th>\n",
       "      <td>36PZC_22_20180405</td>\n",
       "      <td>36PZC_22</td>\n",
       "      <td>/home/ggonzr_cloud/deeplearn/data/ref_landcove...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1508</th>\n",
       "      <td>28QDE_27_20180309</td>\n",
       "      <td>28QDE_27</td>\n",
       "      <td>/home/ggonzr_cloud/deeplearn/data/ref_landcove...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1509 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               image_id   chip_id  \\\n",
       "0     33PWQ_13_20180504  33PWQ_13   \n",
       "1     35NRD_15_20180113  35NRD_15   \n",
       "2     31PGR_26_20181117  31PGR_26   \n",
       "3     34LHJ_20_20180620  34LHJ_20   \n",
       "4     32PPA_20_20180410  32PPA_20   \n",
       "...                 ...       ...   \n",
       "1504  34NBP_29_20180513  34NBP_29   \n",
       "1505  33KXV_05_20180924  33KXV_05   \n",
       "1506  34JBL_26_20180817  34JBL_26   \n",
       "1507  36PZC_22_20180405  36PZC_22   \n",
       "1508  28QDE_27_20180309  28QDE_27   \n",
       "\n",
       "                                      image_folder_path cloud_mask_mean  \n",
       "0     /home/ggonzr_cloud/deeplearn/data/ref_landcove...             0.0  \n",
       "1     /home/ggonzr_cloud/deeplearn/data/ref_landcove...             0.0  \n",
       "2     /home/ggonzr_cloud/deeplearn/data/ref_landcove...             0.0  \n",
       "3     /home/ggonzr_cloud/deeplearn/data/ref_landcove...             0.0  \n",
       "4     /home/ggonzr_cloud/deeplearn/data/ref_landcove...             0.0  \n",
       "...                                                 ...             ...  \n",
       "1504  /home/ggonzr_cloud/deeplearn/data/ref_landcove...        0.000122  \n",
       "1505  /home/ggonzr_cloud/deeplearn/data/ref_landcove...             0.0  \n",
       "1506  /home/ggonzr_cloud/deeplearn/data/ref_landcove...             0.0  \n",
       "1507  /home/ggonzr_cloud/deeplearn/data/ref_landcove...             0.0  \n",
       "1508  /home/ggonzr_cloud/deeplearn/data/ref_landcove...             0.0  \n",
       "\n",
       "[1509 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Guardar el conjunto de test\n",
    "test_df = pd.DataFrame(X_seq_test)\n",
    "test_df.columns = sample_train.columns\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b3584bf-d3ef-4296-b2d5-a0c377ea85e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Almacenar\n",
    "test_df.to_json(f\"{DATA_BASE}/test_set.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e47e9a24-698b-4976-8360-32e4d1a7c32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciar los secuenciadores: En este caso vamos a trabajar con indices\n",
    "train_index_seq = IndexSequence(x_sample_path=X_seq_train)\n",
    "val_index_seq = IndexSequence(x_sample_path=X_seq_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ad390a-cca2-4ae4-8f12-067ee48d139e",
   "metadata": {},
   "source": [
    "## Instanciar el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2f2272-94cd-40e6-a7dd-d130505a09ee",
   "metadata": {},
   "source": [
    "### Versión V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf64d3ff-e981-4a39-8a65-d9271a4b0703",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-06 22:00:24.748442: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "SOURCE_CHANNELS = 3\n",
    "EPOCHS_TRAIN = 10\n",
    "model_v2_shape = (HEIGHT, WIDTH, SOURCE_CHANNELS)\n",
    "model_v2_classes = 7\n",
    "model = build_unet(model_v2_shape, model_v2_classes)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=tf.keras.optimizers.Adam(1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "312601bd-8a76-4adc-a216-8f31e266145a",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "        ModelCheckpoint(\"../models/model_index.h5\", verbose=1, save_best_model=True),\n",
    "        ReduceLROnPlateau(monitor=\"val_loss\", patience=3, factor=0.1, verbose=1, min_lr=1e-6),\n",
    "        EarlyStopping(monitor=\"val_loss\", patience=5, verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02fa5aad-5d52-4c08-9250-f4b926dd2368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento con el arreglo\n",
    "#results = model.fit(X_train, y_train, batch_size=32, epochs=5, callbacks=callbacks,\\\n",
    "#                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f81f87d-b550-418c-9f10-8bc9afa20afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "User settings:\n",
      "\n",
      "   KMP_AFFINITY=granularity=fine,verbose,compact,1,0\n",
      "   KMP_BLOCKTIME=0\n",
      "   KMP_DUPLICATE_LIB_OK=True\n",
      "   KMP_INIT_AT_FORK=FALSE\n",
      "   KMP_SETTINGS=1\n",
      "   OMP_NUM_THREADS=24\n",
      "\n",
      "Effective settings:\n",
      "\n",
      "   KMP_ABORT_DELAY=0\n",
      "   KMP_ADAPTIVE_LOCK_PROPS='1,1024'\n",
      "   KMP_ALIGN_ALLOC=64\n",
      "   KMP_ALL_THREADPRIVATE=128\n",
      "   KMP_ATOMIC_MODE=2\n",
      "   KMP_BLOCKTIME=0\n",
      "   KMP_CPUINFO_FILE: value is not defined\n",
      "   KMP_DETERMINISTIC_REDUCTION=false\n",
      "   KMP_DEVICE_THREAD_LIMIT=2147483647\n",
      "   KMP_DISP_NUM_BUFFERS=7\n",
      "   KMP_DUPLICATE_LIB_OK=true\n",
      "   KMP_ENABLE_TASK_THROTTLING=true\n",
      "   KMP_FORCE_REDUCTION: value is not defined\n",
      "   KMP_FOREIGN_THREADS_THREADPRIVATE=true\n",
      "   KMP_FORKJOIN_BARRIER='2,2'\n",
      "   KMP_FORKJOIN_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_GTID_MODE=3\n",
      "   KMP_HANDLE_SIGNALS=false\n",
      "   KMP_HOT_TEAMS_MAX_LEVEL=1\n",
      "   KMP_HOT_TEAMS_MODE=0\n",
      "   KMP_INIT_AT_FORK=true\n",
      "   KMP_LIBRARY=throughput\n",
      "   KMP_LOCK_KIND=queuing\n",
      "   KMP_MALLOC_POOL_INCR=1M\n",
      "   KMP_NUM_LOCKS_IN_BLOCK=1\n",
      "   KMP_PLAIN_BARRIER='2,2'\n",
      "   KMP_PLAIN_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_REDUCTION_BARRIER='1,1'\n",
      "   KMP_REDUCTION_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_SCHEDULE='static,balanced;guided,iterative'\n",
      "   KMP_SETTINGS=true\n",
      "   KMP_SPIN_BACKOFF_PARAMS='4096,100'\n",
      "   KMP_STACKOFFSET=64\n",
      "   KMP_STACKPAD=0\n",
      "   KMP_STACKSIZE=8M\n",
      "   KMP_STORAGE_MAP=false\n",
      "   KMP_TASKING=2\n",
      "   KMP_TASKLOOP_MIN_TASKS=0\n",
      "   KMP_TASK_STEALING_CONSTRAINT=1\n",
      "   KMP_TEAMS_THREAD_LIMIT=24\n",
      "   KMP_TOPOLOGY_METHOD=all\n",
      "   KMP_USE_YIELD=1\n",
      "   KMP_VERSION=false\n",
      "   KMP_WARNINGS=true\n",
      "   OMP_AFFINITY_FORMAT='OMP: pid %P tid %i thread %n bound to OS proc set {%A}'\n",
      "   OMP_ALLOCATOR=omp_default_mem_alloc\n",
      "   OMP_CANCELLATION=false\n",
      "   OMP_DEFAULT_DEVICE=0\n",
      "   OMP_DISPLAY_AFFINITY=false\n",
      "   OMP_DISPLAY_ENV=false\n",
      "   OMP_DYNAMIC=false\n",
      "   OMP_MAX_ACTIVE_LEVELS=1\n",
      "   OMP_MAX_TASK_PRIORITY=0\n",
      "   OMP_NESTED: deprecated; max-active-levels-var=1\n",
      "   OMP_NUM_THREADS='24'\n",
      "   OMP_PLACES: value is not defined\n",
      "   OMP_PROC_BIND='intel'\n",
      "   OMP_SCHEDULE='static'\n",
      "   OMP_STACKSIZE=8M\n",
      "   OMP_TARGET_OFFLOAD=DEFAULT\n",
      "   OMP_THREAD_LIMIT=2147483647\n",
      "   OMP_WAIT_POLICY=PASSIVE\n",
      "   KMP_AFFINITY='verbose,warnings,respect,granularity=fine,compact,1,0'\n",
      "\n",
      "OMP: Info #211: KMP_AFFINITY: decoding x2APIC ids.\n",
      "OMP: Info #209: KMP_AFFINITY: Affinity capable, using global cpuid leaf 11 info\n",
      "OMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0-23\n",
      "OMP: Info #156: KMP_AFFINITY: 24 available OS procs\n",
      "OMP: Info #157: KMP_AFFINITY: Uniform topology\n",
      "OMP: Info #179: KMP_AFFINITY: 1 packages x 12 cores/pkg x 2 threads/core (12 total cores)\n",
      "OMP: Info #213: KMP_AFFINITY: OS proc to physical thread map:\n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 0 maps to package 0 core 0 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 12 maps to package 0 core 0 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 1 maps to package 0 core 1 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 13 maps to package 0 core 1 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 2 maps to package 0 core 2 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 14 maps to package 0 core 2 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 3 maps to package 0 core 3 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 15 maps to package 0 core 3 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 4 maps to package 0 core 4 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 16 maps to package 0 core 4 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 5 maps to package 0 core 5 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 17 maps to package 0 core 5 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 6 maps to package 0 core 6 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 18 maps to package 0 core 6 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 7 maps to package 0 core 7 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 19 maps to package 0 core 7 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 8 maps to package 0 core 8 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 20 maps to package 0 core 8 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 9 maps to package 0 core 9 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 21 maps to package 0 core 9 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 10 maps to package 0 core 10 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 22 maps to package 0 core 10 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 11 maps to package 0 core 11 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 23 maps to package 0 core 11 thread 1 \n",
      "OMP: Info #249: KMP_AFFINITY: pid 1853 tid 1953 thread 0 bound to OS proc set 0\n",
      "OMP: Info #249: KMP_AFFINITY: pid 1853 tid 2020 thread 1 bound to OS proc set 1\n",
      "OMP: Info #249: KMP_AFFINITY: pid 1853 tid 2021 thread 2 bound to OS proc set 2\n",
      "OMP: Info #249: KMP_AFFINITY: pid 1853 tid 2022 thread 3 bound to OS proc set 3\n",
      "OMP: Info #249: KMP_AFFINITY: pid 1853 tid 2023 thread 4 bound to OS proc set 4\n",
      "OMP: Info #249: KMP_AFFINITY: pid 1853 tid 2024 thread 5 bound to OS proc set 5\n",
      "OMP: Info #249: KMP_AFFINITY: pid 1853 tid 2025 thread 6 bound to OS proc set 6\n",
      "OMP: Info #249: KMP_AFFINITY: pid 1853 tid 2027 thread 8 bound to OS proc set 8\n",
      "OMP: Info #249: KMP_AFFINITY: pid 1853 tid 2026 thread 7 bound to OS proc set 7\n",
      "OMP: Info #249: KMP_AFFINITY: pid 1853 tid 2028 thread 9 bound to OS proc set 9\n",
      "OMP: Info #249: KMP_AFFINITY: pid 1853 tid 2029 thread 10 bound to OS proc set 10\n",
      "OMP: Info #249: KMP_AFFINITY: pid 1853 tid 2030 thread 11 bound to OS proc set 11\n",
      "OMP: Info #249: KMP_AFFINITY: pid 1853 tid 2031 thread 12 bound to OS proc set 12\n",
      "OMP: Info #249: KMP_AFFINITY: pid 1853 tid 2032 thread 13 bound to OS proc set 13\n",
      "OMP: Info #249: KMP_AFFINITY: pid 1853 tid 2033 thread 14 bound to OS proc set 14\n",
      "OMP: Info #249: KMP_AFFINITY: pid 1853 tid 2034 thread 15 bound to OS proc set 15\n",
      "OMP: Info #249: KMP_AFFINITY: pid 1853 tid 2035 thread 16 bound to OS proc set 16\n",
      "OMP: Info #249: KMP_AFFINITY: pid 1853 tid 2036 thread 17 bound to OS proc set 17\n",
      "OMP: Info #249: KMP_AFFINITY: pid 1853 tid 2038 thread 19 bound to OS proc set 19\n",
      "OMP: Info #249: KMP_AFFINITY: pid 1853 tid 2040 thread 21 bound to OS proc set 21\n",
      "OMP: Info #249: KMP_AFFINITY: pid 1853 tid 2039 thread 20 bound to OS proc set 20\n",
      "OMP: Info #249: KMP_AFFINITY: pid 1853 tid 2037 thread 18 bound to OS proc set 18\n",
      "OMP: Info #249: KMP_AFFINITY: pid 1853 tid 2041 thread 22 bound to OS proc set 22\n",
      "OMP: Info #249: KMP_AFFINITY: pid 1853 tid 2042 thread 23 bound to OS proc set 23\n",
      "OMP: Info #249: KMP_AFFINITY: pid 1853 tid 1952 thread 24 bound to OS proc set 0\n",
      "OMP: Info #249: KMP_AFFINITY: pid 1853 tid 2044 thread 26 bound to OS proc set 2\n",
      "OMP: Info #249: KMP_AFFINITY: pid 1853 tid 2045 thread 27 bound to OS proc set 3\n",
      "OMP: Info #249: KMP_AFFINITY: pid 1853 tid 2043 thread 25 bound to OS proc set 1\n",
      "OMP: Info #249: KMP_AFFINITY: pid 1853 tid 2046 thread 28 bound to OS proc set 4\n",
      "OMP: Info #249: KMP_AFFINITY: pid 1853 tid 2048 thread 30 bound to OS proc set 6\n",
      "OMP: Info #249: KMP_AFFINITY: pid 1853 tid 2047 thread 29 bound to OS proc set 5\n",
      "OMP: Info #249: KMP_AFFINITY: pid 1853 tid 2049 thread 31 bound to OS proc set 7\n",
      "OMP: Info #249: KMP_AFFINITY: pid 1853 tid 2050 thread 32 bound to OS proc set 8\n",
      "OMP: Info #249: KMP_AFFINITY: pid 1853 tid 2051 thread 33 bound to OS proc set 9\n",
      "OMP: Info #249: KMP_AFFINITY: pid 1853 tid 2052 thread 34 bound to OS proc set 10\n",
      "OMP: Info #249: KMP_AFFINITY: pid 1853 tid 2053 thread 35 bound to OS proc set 11\n",
      "OMP: Info #249: KMP_AFFINITY: pid 1853 tid 2054 thread 36 bound to OS proc set 12\n",
      "OMP: Info #249: KMP_AFFINITY: pid 1853 tid 2055 thread 37 bound to OS proc set 13\n",
      "OMP: Info #249: KMP_AFFINITY: pid 1853 tid 2056 thread 38 bound to OS proc set 14\n",
      "OMP: Info #249: KMP_AFFINITY: pid 1853 tid 2058 thread 40 bound to OS proc set 16\n",
      "OMP: Info #249: KMP_AFFINITY: pid 1853 tid 2057 thread 39 bound to OS proc set 15\n",
      "OMP: Info #249: KMP_AFFINITY: pid 1853 tid 2059 thread 41 bound to OS proc set 17\n",
      "OMP: Info #249: KMP_AFFINITY: pid 1853 tid 2060 thread 42 bound to OS proc set 18\n",
      "OMP: Info #249: KMP_AFFINITY: pid 1853 tid 2061 thread 43 bound to OS proc set 19\n",
      "OMP: Info #249: KMP_AFFINITY: pid 1853 tid 2062 thread 44 bound to OS proc set 20\n",
      "OMP: Info #249: KMP_AFFINITY: pid 1853 tid 2063 thread 45 bound to OS proc set 21\n",
      "OMP: Info #249: KMP_AFFINITY: pid 1853 tid 2065 thread 47 bound to OS proc set 23\n",
      "OMP: Info #249: KMP_AFFINITY: pid 1853 tid 2064 thread 46 bound to OS proc set 22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3/151 [..............................] - ETA: 17:19 - loss: 2.0043 - accuracy: 0.2012"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:45: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 [==============================] - ETA: 0s - loss: 1.8452 - accuracy: 0.2593"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:45: RuntimeWarning: invalid value encountered in true_divide\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:45: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: saving model to ../models/model_index.h5\n",
      "151/151 [==============================] - 1113s 7s/step - loss: 1.8452 - accuracy: 0.2593 - val_loss: 1.8034 - val_accuracy: 0.2761 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "151/151 [==============================] - ETA: 0s - loss: 1.7369 - accuracy: 0.2724\n",
      "Epoch 00002: saving model to ../models/model_index.h5\n",
      "151/151 [==============================] - 402s 3s/step - loss: 1.7369 - accuracy: 0.2724 - val_loss: 1.7482 - val_accuracy: 0.2773 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "151/151 [==============================] - ETA: 0s - loss: 1.6829 - accuracy: 0.2820\n",
      "Epoch 00003: saving model to ../models/model_index.h5\n",
      "151/151 [==============================] - 401s 3s/step - loss: 1.6829 - accuracy: 0.2820 - val_loss: 1.6702 - val_accuracy: 0.2786 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "151/151 [==============================] - ETA: 0s - loss: 1.6420 - accuracy: 0.3170\n",
      "Epoch 00004: saving model to ../models/model_index.h5\n",
      "151/151 [==============================] - 399s 3s/step - loss: 1.6420 - accuracy: 0.3170 - val_loss: 1.8112 - val_accuracy: 0.1987 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "151/151 [==============================] - ETA: 0s - loss: 1.6079 - accuracy: 0.3413\n",
      "Epoch 00005: saving model to ../models/model_index.h5\n",
      "151/151 [==============================] - 401s 3s/step - loss: 1.6079 - accuracy: 0.3413 - val_loss: 3.3668 - val_accuracy: 0.1876 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "151/151 [==============================] - ETA: 0s - loss: 1.5784 - accuracy: 0.3553\n",
      "Epoch 00006: saving model to ../models/model_index.h5\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "151/151 [==============================] - 401s 3s/step - loss: 1.5784 - accuracy: 0.3553 - val_loss: 3.6848 - val_accuracy: 0.2169 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "151/151 [==============================] - ETA: 0s - loss: 1.5627 - accuracy: 0.3639\n",
      "Epoch 00007: saving model to ../models/model_index.h5\n",
      "151/151 [==============================] - 403s 3s/step - loss: 1.5627 - accuracy: 0.3639 - val_loss: 1.9638 - val_accuracy: 0.1962 - lr: 1.0000e-05\n",
      "Epoch 8/10\n",
      "151/151 [==============================] - ETA: 0s - loss: 1.5599 - accuracy: 0.3655\n",
      "Epoch 00008: saving model to ../models/model_index.h5\n",
      "151/151 [==============================] - 408s 3s/step - loss: 1.5599 - accuracy: 0.3655 - val_loss: 1.8813 - val_accuracy: 0.2814 - lr: 1.0000e-05\n",
      "Epoch 00008: early stopping\n",
      "Tiempo del entrenamiento: 3934.9867 seconds\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento con secuenciadores\n",
    "tic = time.perf_counter()\n",
    "results = model.fit(\n",
    "    x=train_index_seq,\n",
    "    validation_data=val_index_seq,\n",
    "    epochs=EPOCHS_TRAIN,\n",
    "    callbacks=callbacks,\n",
    "    use_multiprocessing=True\n",
    ")\n",
    "\n",
    "toc = time.perf_counter()\n",
    "print(f\"Tiempo del entrenamiento: {toc - tic:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20516df0-9afa-496e-a860-22aca566a19e",
   "metadata": {},
   "source": [
    "# Next section"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
